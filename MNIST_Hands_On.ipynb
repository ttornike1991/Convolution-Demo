{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ttornike1991/Convolution-Demo/blob/main/MNIST_Hands_On.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MNIST Hands-On"
      ],
      "metadata": {
        "id": "EVVr2fDV_czT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QPB_9IUfdeeQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Imports"
      ],
      "metadata": {
        "id": "rphK8HcTCM3W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAZd3P7p_cES"
      },
      "outputs": [],
      "source": [
        "# TODO: Import torch and torchvision's transforms\n",
        "# TODO: Import numpy as np\n",
        "%matplotlib inline\n",
        "from tqdm import tqdm\n",
        "from time import time\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Helper Functions"
      ],
      "metadata": {
        "id": "OZoz4pnR_9jc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Displays an image \"\"\"\n",
        "def display(image):\n",
        "    print(f\"Image Size: {image.shape}\")\n",
        "    plt.imshow(image, cmap=\"gray\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "voGOKxAt_9Ia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Global Constants"
      ],
      "metadata": {
        "id": "KUV_CB-R80Bp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.01\n",
        "epochs = 100\n",
        "batch_size = 64\n",
        "home_dir = \"/content\"\n",
        "dataset_path = f\"{home_dir}\"\n",
        "# TODO: define the device being used\n",
        "# device = "
      ],
      "metadata": {
        "id": "wDE2BSq981wi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Preprocessing"
      ],
      "metadata": {
        "id": "dDzorixiue1s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the implementation of the preprocessing transform function \n",
        "#       by adding other transformations (hint: lock up pytorch's normalization transform)\n",
        "#       try adding other transformations to see what happens!\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),\n",
        "    ]\n",
        ")\n",
        "\n",
        "# validation set of (image, label)\n",
        "val_set = datasets.MNIST(dataset_path, download=True, train=False, transform=transform)\n",
        "# training set of (image, label)\n",
        "train_set = datasets.MNIST(dataset_path, download=True, train=True, transform=transform)\n",
        "\n",
        "# DataLoader nicely organizes our dataset into batches and loads them rightup\n",
        "val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# uncomment to visualize around with training dataset\n",
        "# for i in range(0, 3):\n",
        "#     image, label = train_set[i]\n",
        "#     display(image[0])"
      ],
      "metadata": {
        "id": "7uYAa3PhuhSa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Forward Propogation"
      ],
      "metadata": {
        "id": "bMV0zOoFCdVj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the implementation of the forward propogation function\n",
        "'''\n",
        "Computes what number the model predicts image x is of\n",
        "\n",
        "Inputs\n",
        "  :model: the model used to predict\n",
        "  :x: tensor representation of the image containing a number \n",
        "\n",
        "Outputs\n",
        "  :returns: <torch.tensor> of probabilities\n",
        "'''\n",
        "def forward(model, x):\n",
        "  # TODO: compute result of first convolution\n",
        "  output = model.conv_1(x)\n",
        "  # output = \n",
        "\n",
        "  # TODO: compute result of second convolution\n",
        "  # output = \n",
        "\n",
        "  return model.out(output.view(output.size(0), -1))"
      ],
      "metadata": {
        "id": "hTbBQBovCfQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Model"
      ],
      "metadata": {
        "id": "iEtgimJ_CW5c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MNIST_CNN(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(MNIST_CNN, self).__init__()\n",
        "\n",
        "        ### First set of convolution ###\n",
        "        self.conv_1 = torch.nn.Conv2d(\n",
        "          stride = 1,          # we will convolve all of the image                 \n",
        "          padding = 2,\n",
        "          in_channels = 1,     # we are sending in grayscale images with only 1 channel (1 image)  \n",
        "          kernel_size = 5,     # the size of the first set of kernels       \n",
        "          out_channels = 16,   # we output 16 filtered images\n",
        "          # number of output images each of \n",
        "          # size = (input_width − kernel_size + 2(padding_size)) / (stride) + 1\n",
        "          #      = (28 - 5 + 2(2)) / 1 + 1 = 28\n",
        "\n",
        "        )\n",
        "        self.act_1 = torch.nn.ReLU() # the activation for non-linearity    \n",
        "        self.pool_1 = torch.nn.MaxPool2d(\n",
        "          stride = 2,         \n",
        "          # we will convolve every other pixel splitting the size of the image by half\n",
        "          # size = 28 / 2 = 14\n",
        "          kernel_size = 2 # size of pooling kernel\n",
        "        ) \n",
        "        \n",
        "        ### Second set of convolution ###\n",
        "        self.conv_2 = torch.nn.Conv2d(\n",
        "          stride = 1,          # we will convolve all of the image          \n",
        "          padding = 2,         # how many pixels to add in each direction\n",
        "          kernel_size = 5,     # the size of the second set of kernels\n",
        "          in_channels = # TODO: what are number of in_channels,\n",
        "          out_channels = 32,   # we output 32 filtered images\n",
        "          # number of output images each of \n",
        "          # size = (input_width − kernel_size + 2(padding_size)) / (stride) + 1\n",
        "          #      = (14 - 5 + 2(2)) / 1 + 1 = 14\n",
        "        )     \n",
        "\n",
        "        self.act_2 = torch.nn.ReLU() # the activation for non-linearity                    \n",
        "        self.pool_2 = torch.nn.MaxPool2d(\n",
        "          stride = 2,         \n",
        "          # we will convolve every other pixel splitting the size of the image by half\n",
        "          kernel_size = 2 # size of pooling kernel\n",
        "        )    \n",
        "        \n",
        "        ### Fully prediction connected layer ###\n",
        "        self.out = torch.nn.Linear(\n",
        "          out_features = 10, # 10 possibilte outcomes (0, 1, 2, 3, 4, 5, 6, 7, 8, 9)\n",
        "          in_features = # TODO: how many input features do we have, (what is overall size of our images and how many do we have),  \n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return forward(self, x)"
      ],
      "metadata": {
        "id": "uqPSQg4OCYRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Back Propogation"
      ],
      "metadata": {
        "id": "uzT6VOHLCn8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Complete the implementation of the back propogation function\n",
        "'''\n",
        "Trains a CNN classifier on the MNIST dataset\n",
        "\n",
        "Inputs\n",
        "  :model: CNN classifier\n",
        "  :data_loader: a set of paired tuples (image, label)\n",
        "'''\n",
        "def train(model, data_loader, optimizer = None):\n",
        "  # TODO: define the loss function to be cross-entropy loss\n",
        "  # loss_func = \n",
        "  \n",
        "  # the optimizer is what solves the optimization problem \n",
        "  # to update the network's kernel's and weights\n",
        "  if optimizer is None: optimizer = torch.optim.Adam(model.parameters(), lr = lr)\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    for i, (image_batch, labels) in enumerate(data_loader):\n",
        "      # TODO: move image_batch to device\n",
        "      # TODO: move labels to device\n",
        "\n",
        "      # TODO: compute the model's output\n",
        "      # output = \n",
        "\n",
        "\n",
        "      # print(f\"\\n[out] >> {output.shape}\")    \n",
        "      # print(f\"[labels] >> {labels.shape}\")\n",
        "\n",
        "      # TODO: compute the loss between the output and labels\n",
        "      # loss = \n",
        "      \n",
        "      # TODO: clear gradients for this training step   \n",
        "      # TODO: backpropagation, compute gradients                 \n",
        "      # TODO: apply gradients to update our kernels      \n",
        "      \n",
        "    if epoch % 100 == 0:\n",
        "        print (f\"\\nEpoch [{epoch}/{epochs}], Loss: {loss.item():.4f}\")\n",
        "\n",
        "cnn = MNIST_CNN()\n",
        "cnn.to(device)\n",
        "train(cnn, train_loader)"
      ],
      "metadata": {
        "id": "P-kgPAuICqmh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test\n",
        "\n",
        "Test your model by running the script below!"
      ],
      "metadata": {
        "id": "9ZKyszwIXFFn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (image_batch, labels) in enumerate(train_loader):\n",
        "  labels = labels.to(device)\n",
        "  image_batch = image_batch.to(device)\n",
        "\n",
        "  prediction = cnn(image_batch)\n",
        "\n",
        "  image_tensor = image_batch[0]\n",
        "  # TODO: convert image_tensor into numpy image_array\n",
        "  # image_array = \n",
        "  display(image_array[0])\n",
        "  print(f\">> Prediction: {prediction[0].argmax()}\\n\\n\")\n",
        "  if i > 3: break"
      ],
      "metadata": {
        "id": "tUgRhHm1Vmh9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}